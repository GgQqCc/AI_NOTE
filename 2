

RLVR+VLA 挑战点：现实世界数据采集和泛化性问题。（仿真迁移到真实世界难题）

奖励函数设计的复杂度：为复杂任务设计能够引导模型学习正确子目标的Dense 非稀疏奖励函数难度大。（暂不涉及）

PPO+RL：训练不稳定，收敛困难。

VLA模型本身推理速度慢，（高分辨率，长指令等）。RL循环每一步都要进行一次完整VLA模型前向传播决定动作，Rollout阶段效率较低。算力要求高。





### 1. 训练（Training）阶段

**训练阶段的主要目的：**

- 让模型学习大量数据中的模式、语言结构和知识，通过调整模型内部的参数（权重和偏置），使其能够准确地完成特定任务（如文本生成、问答、翻译等）。

**训练阶段在做什么：**

1. **数据输入与前向传播（Forward Pass）：** 将大规模的训练数据集输入模型。数据流经模型的各个层，进行计算，最终输出一个预测结果。
2. **计算损失（Calculate Loss）：** 将模型的预测结果与数据的真实标签（或目标值）进行比较，计算出**损失值（Loss）**。损失值代表了模型预测的准确性，损失值越小，模型性能越好。
3. **反向传播（Backward Pass）：** 根据损失值，使用**梯度下降（Gradient Descent）**等优化算法，计算模型中所有参数对于损失的梯度（即损失随参数变化的速度）。
4. **参数更新（Parameter Update）：** 沿着梯度的反方向微调模型的参数，使损失值在下一次迭代中减小。
5. **迭代（Iteration）：** 重复以上步骤，直到模型性能达到满意水平或达到预设的训练周期（Epoch）。

**训练阶段涉及的归一化（Normalization）环节主要在做什么：**

- **归一化（Normalization）**在训练阶段是至关重要的技术，它通常指的是在模型内部，对某一层的输入或输出进行调整，使其特征的均值接近 0、方差接近 1。
- **目的：**
  - **加速训练收敛：** 标准化输入分布，可以使模型更快地找到最优解。
  - **稳定训练过程：** 尤其是在深度网络中，可以减轻“内部协变量偏移”（Internal Covariate Shift）问题，防止梯度消失或爆炸。
  - **允许更高的学习率：** 在不导致训练发散的情况下使用更高的学习率。
- **常见类型：** 在LLM中，最常见的是 **层归一化（Layer Normalization, text{LN}）**，它对同一层内的所有神经元（特征维度）进行归一化。



### 2. 推理（Inference）阶段



**推理阶段的主要目的：**

- 将训练好的模型部署到实际应用中，利用其学到的知识和能力，对新的、未见过的数据（输入）生成有意义的输出（如回答问题、生成文本、分类等）。

**推理阶段在做什么：**

1. **输入（Input）：** 将用户输入（例如一个问题或一个指令）提供给模型。
2. **前向传播（Forward Pass）：** 输入数据流经模型（此时模型的参数是固定不变的），仅进行计算，不进行参数更新。
3. **输出生成（Output Generation）：** 模型根据输入数据和已学习的参数，生成最终的预测结果或输出序列。
4. **解码（Decoding）：** 对于生成式大模型（如 text{GPT}、text{LLaMA}），推理过程通常涉及**自回归**地逐个生成 text{Token}（词语或子词），直到生成结束标记或达到最大长度。

**推理阶段涉及的归一化和反归一化环节主要在做什么：**

- **归一化（Normalization）：**
  - **延续训练：** 推理时仍然需要执行训练时所使用的**内部归一化**（如 **层归一化**）。这是因为模型的参数是在归一化后的数据分布上训练的，如果不进行同样的归一化，模型的内部激活值就会和训练时不一样，导致性能严重下降。
  - **处理输入：** 此外，输入到模型的原始数据（如词嵌入 text{Embedding}）也必须遵循训练时的**预处理**（Pre-processing）步骤，如 text{Token} 化、填充（Padding）等。
- **反归一化（De-normalization）：**
  - **场景：** “反归一化”这个术语在LLM的上下文中，**更多地是指将模型的最终输出从内部表示转换回人类可读的形式**，而不是一个严格的数学逆运算。
  - **具体操作：**
    1. **text{Token} 到文本的转换：** 模型在推理阶段输出的是一串数字化的 text{Token ID}。**反归一化**的关键步骤是使用**词汇表（Vocabulary）**或 text{Tokenizer} 将这些 text{ID} 映射回实际的词语或子词，从而得到最终的文本输出。
    2. **特殊应用：** 如果模型被训练来预测数值型结果（例如，在某些非文本任务中），且该结果在训练前被归一化了，那么在推理的最后一步，确实需要进行数学上的**反归一化**操作，将预测值从 [0, 1] 或 mathcal{N}(0, 1) 的范围转换回原始的尺度和单位。但在标准LLM的文本生成任务中，主要进行的是 text{Token ID} 到文本的映射。



### 总结表格



| **阶段** | **主要目的**           | **核心操作**                           | **归一化（Normalization）**                                  | **反归一化（De-normalization）** |
| -------- | ---------------------- | -------------------------------------- | ------------------------------------------------------------ | -------------------------------- |
| **训练** | 学习数据模式，调整参数 | 前向传播、计算损失、反向传播、参数更新 | **内部归一化**（如 text{Layer Norm}），稳定和加速训练        | **不涉及**（模型产出的是参数）   |
| **推理** | 应用已学知识，生成输出 | 前向传播、自回归解码                   | **内部归一化**（如 text{Layer Norm}），保持与训练时数据分布一致 | **主要指 text{Token ID} 到**     |







全监督学习FSL：数据集每个样本，精确、高质量的人工标注标签。

弱监督学习WSL：样本标签不完成不精确 (1)小部分标注，大部分无标签 （2）粗粒度标签，不精确到像素和个体 （3）不准确，有噪声

包括多示例学习，标签去噪

自监督学习SSL：完全没有人工标签，模型利用数据自身结构关系，自动生成伪标签进行学习。

经典SSL任务：

1、NLP的MLM（掩码语言建模），预测被随机遮盖住的词语。

2、NLP-GPT：NTP（下一个词语预测）

3、CV拼图（Jigsaw)：图片分成几块打乱顺序，模型恢复原图

4、CV对比（SimCLR）:对同一张图片进行不同方式的增强（如裁剪、变色），让模型学习使增强后的两张图的特征表示相似，同时远离其他图片的特征表示。

对同一张图片进行不同方式的增强（如裁剪、变色），让模型学习使增强后的两张图的特征表示相似，同时远离其他图片的特征表示。

提取图像语义和不变特征，学习鲁棒性特征。

自监督目标：通过代理任务（下一个词预测等）学习通用、可迁移的特征表示。应用：模型的**预训练**阶段，用于初始化一个强大的特征提取器。

弱监督目标：通过设计特定的**算法**来处理**弱标签**，以解决特定的**下游任务**（如图像分类）。应用：**模型训练**或**微调**阶段，用于解决实际应用问题。



GPT： 生成式 预训练 Transformer

BERT：基于 Transformer的双向编码器表示







### 特征提取主要是在做什么？



在 text{Transformer} 模型中，**特征提取**主要发生在模型堆叠的 text{Encoder} 或 text{Decoder} 层中，核心机制是**自注意力机制 (text{Self-Attention Mechanism})**。



#### 1. 主要目标：生成上下文相关的特征表示



特征提取的主要目标不是简单地将词语映射为向量，而是要将**原始的、静态的词嵌入**，转化为**富含上下文信息的动态向量表示**。

- **静态特征（输入）：** “苹果”这个词的原始词嵌入是固定的，无论它在句子中表示水果还是公司。
- **动态特征（输出）：** text{Transformer} 提取的特征是动态的。如果句子是“我喜欢吃**苹果**”，模型会提取出与“水果”相关的特征；如果句子是“我买了**苹果**手机”，模型会提取出与“科技公司”相关的特征。



#### 2. 核心作用：捕获依赖关系



特征提取的核心在于**捕获序列中任意两个 text{Token} 之间的复杂依赖关系**，无论它们在序列中相隔多远。这是 text{RNN} 和 text{CNN} 难以高效做到的。

- **长距离依赖 (Long-range Dependencies)：** 模型可以同时考虑句子开头和结尾的词语，从而在提取特征时获得全局视角。

------



### 三、 特征提取是如何实现的？（基于自注意力机制）



text{Transformer} 通过**多头自注意力机制**来实现高效、上下文相关的特征提取。



#### 1. 三个核心向量：text{Q}、text{K}、text{V}



对于输入序列中的每个 text{Token} 向量 x_i，模型会通过三个独立的线性变换（即三个权重矩阵 W^Q, W^K, W^V），将其转换为三个不同的向量：

- **查询向量 (text{Query}, Q)：** 代表当前 text{Token} **想知道**的信息。
- **键向量 (text{Key}, K)：** 代表当前 text{Token} 可以**提供**的信息。
- **值向量 (text{Value}, V)：** 包含了当前 text{Token} 携带的**真正信息**。



#### 2. 特征提取的核心公式（注意力计算）



特征提取的过程，就是计算序列中所有 text{Token} 对当前 text{Token} 的**贡献度**，然后将这些贡献度加权求和。

text{Attention}(Q, K, V) = text{Softmax}left(frac{Q K^{top}}{sqrt{d_k}}right) V

- **相似度/注意力得分 left(frac{Q K^{top}}{sqrt{d_k}}right)：**
  - 将当前 text{Token} 的 text{Query} 向量 Q 与**所有** text{Token} 的 text{Key} 向量 K 进行点积计算相似度。
  - **结果：** 得到一个**注意力权重矩阵**，矩阵中的每个值表示序列中其他 text{Token} 对当前 text{Token} 的关注程度。
- **归一化 (text{Softmax}):**
  - 将注意力得分通过 text{Softmax} 函数归一化，得到 0 到 1 之间的**概率分布**，即实际的**注意力权重**。
- **加权求和 (V):**
  - 将这些权重应用于**所有** text{Token} 的 text{Value} 向量 V 上，并求和。
  - **结果：** 得到当前 text{Token} 的**新的、上下文相关的特征向量**。



#### 3. 多头机制（Multi-Head）



**多头自注意力**意味着这一过程会**并行重复**多次（如 h=8 次）。

- **目的：** 每个“头”负责学习输入序列中**不同方面**的依赖关系或特征表示（例如，一个头关注语法关系，另一个头关注语义关系）。
- **实现：** 将 h 个头计算出的特征向量拼接起来，再通过一个线性变换得到该层的最终输出特征。

通过这种方式，text{Transformer} 在每一层都能**高效且并行地**整合全局信息，将原始的词嵌入一步步精炼成高度抽象和语义丰富的特征表示。







《text{Attention Is All You Need}》自注意力机制 	

**完全抛弃**传统的循环结构（text{RNN}）和卷积结构（text{CNN}），而只依赖**注意力机制**来处理序列数据。







传统的循环结构（text{RNN}）和卷积结构（text{CNN}）是如何处理序列数据的，并对比它们相对于注意力机制的优势和劣势。



### 一、 循环结构（text{RNN}/text{LSTM}/text{GRU}）



**如何处理序列数据：**

循环神经网络 (text{RNN}) 采用一种**顺序的、递归的**处理方式。它通过一个**隐藏状态（text{Hidden State}）**来捕获序列信息：

1. **逐词处理：** text{RNN} 从序列的第一个 text{Token} 开始，**逐个**向后处理。
2. **记忆机制：** 每处理一个 text{Token}，模型都会更新其**隐藏状态**。这个隐藏状态可以被看作是模型对**到目前为止**的序列信息的一个“记忆”或“总结”。
3. **信息传递：** 当前 text{Token} 的隐藏状态 h_t 是由**当前输入 x_t** 和**前一个时刻的隐藏状态 h_{t-1}** 共同计算得出的。

**比喻：** 就像一个人在听一个长故事，他必须一个字一个字地听，并把当前听到的内容和之前记住的内容结合起来理解。



#### 优势 (相较于早期的 text{NLP} 方法)：

- **天然的序列处理能力：** 结构上天然适合处理变长序列和时间序列数据。
- **参数共享：** 无论序列多长，都使用同一组权重进行循环计算，模型参数量相对较小。



#### 劣势 (相较于注意力机制)：

1. **无法并行计算（text{Slow}）：** 最大的缺陷。由于当前步的计算依赖于前一步的隐藏状态，text{RNN} 必须**串行**工作，无法利用 text{GPU} 的大规模并行计算能力，导致训练速度非常慢。
2. **长距离依赖问题：** 尽管 text{LSTM} 和 text{GRU} 对 text{RNN} 进行了改进，但在处理极长的序列时，信息经过多次循环传递后仍然会逐渐衰减。模型难以有效连接序列开头和结尾的词语，导致**信息丢失**。
3. **信息压缩瓶颈：** 整个序列的信息被强制压缩到一个**固定长度的隐藏状态**向量中，难以完整地捕获所有细节。





### 二、 卷积结构（text{CNN}）

**如何处理序列数据：**

卷积神经网络 (text{CNN}) 主要通过**滑动窗口（text{Kernel}/text{Filter}）**来提取序列特征。

1. **局部特征提取：** text{CNN} 使用一个小的卷积核，在序列上进行滑动操作。每次操作只关注一个**固定大小的局部窗口**（例如：只看相邻的三个词）。
2. **多层堆叠：** 为了捕获长距离信息，需要堆叠多层 text{CNN}。通过多层堆叠，每一层的输出都会覆盖更大的感受野，从而间接捕获全局信息。

**比喻：** 就像一个人在看句子时，一次只聚焦在三四个相邻的词上（如“很好吃”），然后将这些局部理解一层层往上传递。



#### 优势 (相较于 text{RNN})：



- **并行计算：** text{CNN} 可以同时在序列的不同位置上执行卷积操作，因此具有**并行计算**的能力，训练速度比 text{RNN} 快。
- **局部特征提取强：** 非常擅长捕捉局部模式，例如短语、text{N}-text{gram} 特征等。



#### 劣势 (相较于注意力机制)：



1. **难以捕获长距离依赖：** 捕获长距离依赖需要**深层堆叠**很多层，这增加了模型深度，但效率和表达力仍不如自注意力。
2. **特征缺乏上下文感知：** 尽管 text{CNN} 的输出是上下文相关的，但其核心卷积操作是基于**固定、局部**的窗口。它不像注意力机制那样，能动态地、有选择性地将信息从序列的**任意位置**聚合过来。

------



### 三、 注意力机制（text{Transformer}）的优势



text{Transformer} 模型的自注意力机制直接针对性地解决了 text{RNN} 和 text{CNN} 的核心缺陷，因此被称为序列处理的革命：

| **特性**       | **RNN/LSTM**         | **CNN**              | **自注意力（Transformer）**          |
| -------------- | -------------------- | -------------------- | ------------------------------------ |
| **计算模式**   | **串行**（顺序计算） | **并行**（局部窗口） | **高度并行**（全局同时计算）         |
| **长距离依赖** | 难以捕获，信息衰减   | 需深层堆叠，间接捕获 | **一步到位，直接连接**（无信息衰减） |
| **上下文感知** | 基于前序的隐藏状态   | 基于固定的局部窗口   | **动态、全局感知**，权重根据输入变化 |
| **训练速度**   | 慢                   | 较快                 | **极快**（充分利用 text{GPU}）       |

**总结 text{Transformer} 的核心优势：**

1. **极速训练：** 由于完全并行，text{Transformer} 可以高效地处理大规模数据，使得训练具有**亿级甚至万亿级参数**的大模型成为可能。
2. **全局信息整合：** 它能够**一步**捕捉序列中任意两个 text{Token} 之间的依赖关系，避免了信息在长距离传递中的丢失，极大地提高了模型对长文本的理解能力。







“**特征**”是对**研究对象本质属性的定量描述**   

比如汽车的颜色、品牌、功率、座椅数量等等，都是它的特征。

通过词嵌入 **“将离散的词语映射到连续的低维向量空间，并利用上下文信息捕获词语的语义关系。”**



NLP和Transformer中，特征是向量，



稀疏Sparse和稠密Dense向量的区别是向量中0 值的多少。

向量(1列或者1行数)



阶数：阶是张量的阶数，表示该量需要索引的个数。

标量：0个索引，0阶张量

向量：1个索引，1阶张量。

矩阵：2个索引，2阶张量。

深度学习中，张量的“阶”代表了我们组织数据的**层次结构**

(text{Batch}, text{Channels}, text{Height}, text{Width}) 4阶







“Diffusion Policy” (扩散策略) 是一个在**机器人学习（Robot Learning）**和**模仿学习（Imitation Learning）**领域中非常前沿和强大的概念，它将近年来在图像生成领域大放异彩的**扩散模型（Diffusion Models）**应用到了机器人的动作控制策略上。

简单来说，它的核心思想是：



### 核心思想：将动作预测视为“去噪”过程

求解逆向SDE（随机微分方程）或者ODE（常微分方程）  去噪过程分为调度和采样器。

噪声调度：步进路线，均匀去噪还是先快后满

采样器：执行具体去噪手法，欧拉法、海恩法来实现每一步去噪

在机器人模仿学习中，策略（Policy）的目标是根据当前的视觉观察（Observation）来预测机器人下一步或未来一段时间的**动作序列（Action Sequence）**。

传统的模仿学习方法，如直接回归或使用混合高斯模型（GMM），在处理以下问题时会遇到困难：

1. **多模态性（Multimodality）：** 对于同一个观察状态，可能存在多种合理的后续动作（例如，拿起一个杯子可以从左边或右边靠近）。传统方法往往会把这些不同的“模式”平均化，导致机器人做出模糊或不明确的动作。
2. **动作序列的连贯性：** 预测单个时间步的动作容易，但要预测一整个平滑、连贯、且对时间有依赖的动作序列是很困难的。

**Diffusion Policy 的解决方式：**

它不像传统方法那样直接预测动作，而是将动作预测转化为一个**条件去噪扩散过程**：

1. **噪声开始：** 策略的输入不是直接的动作，而是一段**纯随机噪声**（代表一个完全随机的动作序列）。
2. **迭代去噪：** 模型（通常是一个 U-Net 或 Transformer）被训练来**迭代地去除**这段噪声。在每一次去噪过程中，模型都会以当前的**视觉观察**为条件，朝着一个“合理的”动作序列的方向微调。
3. **最终输出：** 经过多次迭代去噪后，噪声最终被转化为一个**平滑、连贯且有效的**动作序列。



### 关键优势



Diffusion Policy 能够带来显著的性能提升，尤其是在复杂的机械臂操作任务中：

1. **完美处理多模态动作：** 扩散模型天生擅长建模复杂的多模态分布。对于同一观察，策略可以**采样**出多个不同的、但都合理的动作序列，而不是将它们平均化。这使得机器人的行为更加灵活和像人类。
2. **预测时间连贯的序列：** 它不是预测单个动作，而是直接预测**一整个动作序列**。这保证了动作在时间上的平滑性和一致性，非常适合需要复杂协调操作的任务（如翻转马克杯、涂酱料等）。
3. **训练稳定性高：** 相比于一些其他生成模型（如能量基模型），扩散模型在训练过程中更加稳定。
4. **适用高维动作空间：** 能够优雅地处理复杂的、高维度的动作空间（例如 6 自由度以上的末端执行器控制）。



### 总结

| **特点**     | **描述**                                                     |
| ------------ | ------------------------------------------------------------ |
| **应用领域** | 机器人学、模仿学习（Imitation Learning）、视觉运动控制（Visuomotor Control） |
| **核心机制** | 将**动作序列预测**建模为**条件去噪扩散过程**。               |
| **模型基础** | 基于**去噪扩散概率模型（DDPM）**，通常使用 **Transformer** 或 **U-Net** 作为骨干网络。 |
| **主要贡献** | 显著提高了机器人策略在**多模态性**和**时间连贯性**上的表现，在多种机械臂操作任务中超越了此前的 SOTA 方法。 |



Pytorch深度学习框架，不会tensorflow。

torch.zeros(2,3)

torch.ones(2,3)

torch.rand(2,3)

numpy_array=np.array([1,2],[2,3])

tensor_from_array=torch.from_numpy(numpy_array)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

d = torch.randn(2,3,device = device)



张量逐元素加减乘 都是 +-*直接

转置：g=torch.randn(2,3)        

g.t() 或者g.transpose(0，1)

**print**(g.shape) # 返回形状



权重矩阵是神经网络中**存储和学习知识**的核心部分，它定义了网络层与层之间神经元连接的强度。

权重矩阵中每个元素（权重w）都表示上一层的一个神经元和当前层的神经元之间的连接强度。

向传播过程中，权重矩阵用于将输入信号进行**线性组合**，决定了输入数据中的哪些特征对于当前层的输出是重要的。

Z = W * A + b

b偏置向量 A上一层输入，W 权重矩阵， Z线性组合结果，净输入。

### 学习机制

在神经网络的训练过程中，**权重矩阵 W 和偏置向量 b** 就是需要通过反向传播和优化器（如梯度下降）来不断调整和优化的参数。

- **知识存储：** 神经网络学到的所有“知识”或“模式识别”能力，最终都体现在这些权重矩阵的数值上。



## 什么是激活函数（Activation Function）？

激活函数是一个非线性函数，它作用于线性组合的结果 Z，引入**非线性**能力，这是神经网络能够解决复杂问题的关键。

### A. 作用与定义

- **定义：** 激活函数 sigma接收线性组合的结果 Z 作为输入，并将其转换为当前层的**激活值 A**（即当前层的输出）。
- **核心作用：**
  1. **引入非线性：** 如果没有激活函数（或者只使用线性激活函数），无论网络有多少层，它都只能执行线性变换，相当于只做了一次矩阵乘法。引入非线性后，网络才具备拟合任何复杂函数的能力（即万能近似定理）。
  2. **控制输出范围：** 有些激活函数（如 Sigmoid 和 Tanh）能将输出值压缩到特定的范围内，便于梯度计算和模型稳定。



### B. 数学表示



它将线性组合结果 Z映射为当前层的激活值 A：

A = sigma(Z)

- A: 当前层的激活值（Activation）。
- sigma: 激活函数。
- Z: 线性组合结果。



### C. 常见的激活函数

![image-20251021145205861](C:/Users/g30030161/AppData/Roaming/Typora/typora-user-images/image-20251021145205861.png)

简而言之：

- **权重矩阵**负责**线性地**结合特征，是**模型学习的参数**。
- **激活函数**负责引入**非线性**，是**模型能力的保证**。



非线性层都有激活函数。输出层 回归问题不需要激活函数，分类问题需要softmax或者sigmoid

反向传播

**反向传播（Backpropagation）\**是一种高效的算法，用于计算\**损失函数**（Loss Function）相对于网络中所有**权重**（Weights）和**偏置**（Biases）的**梯度**（Gradients）。

根据正向传播计算的损失，在反向传播中对权重和偏置的梯度进行调整。  这就是一次神经网络迭代。



**计算“方向”：** 确定网络中的每一个参数应该如何调整（增大还是减小，以及调整多少），才能使得最终的**损失函数值**降低。

反向传播是基于前面提到的**链式法则（Chain Rule）**，在一个被称为**计算图**（Computational Graph）的结构上，以**逆序**的方式进行数据流动和计算：

1. **前向计算 (Forward Pass)：** 输入数据通过网络，计算出预测结果 Y'和最终的损失 L。在这个过程中，自动求导系统记录了所有的操作和中间结果。
2. **反向计算 (Backward Pass)：**
   - 从损失 L 开始，将梯度（视为误差信号）传回最后一层。
   - 在每一层，算法将**上游传来的梯度**与该层的**局部梯度**（该层输出对输入的偏导数）相乘。
   - 梯度逐层向后传递，直到输入层。
3. **结果：** 算法最终计算出 frac{\partial L}{\partial W}（损失对权重的梯度），这个梯度就是损失函数在当前参数位置上的**最陡峭上升方向**。我们需要沿着其**反方向**（负梯度）更新参数。

简而言之，反向传播是**梯度计算的机制**。

### 回归任务损失函数（预测一个连续的数值）

房价、天气、股票等

均方误差 MSE 最常用，对大误差惩罚力度大，梯度平滑利于优化

平均绝对误差 MAE， L1 loss，

Huber 结合L1 L2优点， 误差小时使用L2平滑，误差大使用L1稳健





分类任务的目标是预测数据点属于哪个**离散的类别**。

分类任务损失函数：

二元分类（0,1问题） 二元交叉熵  BCE loss 

![image-20251021153527284](C:/Users/g30030161/AppData/Roaming/Typora/typora-user-images/image-20251021153527284.png)



多元分类，C>2

![image-20251021153549879](C:/Users/g30030161/AppData/Roaming/Typora/typora-user-images/image-20251021153549879.png)

  ![image-20251021153650615](C:/Users/g30030161/AppData/Roaming/Typora/typora-user-images/image-20251021153650615.png)



优化器：

基础梯度下降：

| **优化器**         | **简称**                                        | **核心机制**                                                 | **特点与缺点**                                               |
| ------------------ | ----------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **梯度下降**       | **GD** (Gradient Descent)                       | 使用**整个**训练集计算梯度，然后更新一次参数。               | **计算准确**。但对于大型数据集，计算开销巨大，效率低下。     |
| **随机梯度下降**   | **SGD** (Stochastic Gradient Descent)           | **每处理一个样本**就计算梯度并更新一次参数。                 | **更新速度快**。但梯度波动大，损失函数震荡严重，难以收敛到精确最小值。 |
| **小批量梯度下降** | **Mini-batch GD** (Mini-batch Gradient Descent) | **每处理一小批（Mini-batch）样本**就计算平均梯度并更新一次参数。 | **平衡了速度和稳定性**。这是目前深度学习中默认和最常用的“SGD”形式。 |



基于动量的优化器：

动量机制引入了惯性，使参数更新方向不仅取决于当前的梯度，还取决于历史梯度的平均值，以加速收敛并减少震荡。

| **优化器**            | **简称**                                | **核心机制**                                                 | **优点**                                            |
| --------------------- | --------------------------------------- | ------------------------------------------------------------ | --------------------------------------------------- |
| **动量法**            | **Momentum**                            | 引入**动量项**（gamma），使模型在梯度方向一致时加速，梯度方向改变时减速。 | 有效加速 SGD 的收敛，帮助模型跳出浅层的局部极小值。 |
| **Nesterov 加速梯度** | **NAG** (Nesterov Accelerated Gradient) | 一种改进的动量法。它不沿着当前位置的梯度方向移动，而是沿着**预期位置**的梯度方向移动（向前看一步）。 | 比标准动量法收敛更快、更稳定。                      |

自适应学习率（Adaptive Learning Rate）优化器

这类优化器为**每个参数**维护一个独立的学习率，并根据该参数的历史梯度信息来调整其学习率，这极大地简化了学习率的手动调整。

| **优化器**   | **简称**                                   | **核心机制**                                                 | **优点与局限性**                                             |
| ------------ | ------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **AdaGrad**  | **AdaGrad** (Adaptive Gradient)            | 基于历史梯度的平方和来自适应地调整学习率。梯度大的参数，学习率衰减得快；梯度小的参数，学习率衰减得慢。 | **适用于稀疏数据**（如 NLP）。但学习率会单调递减到零，可能导致训练提前停止。 |
| **RMSprop**  | **RMSprop** (Root Mean Square Propagation) | 改进 AdaGrad，使用**指数加权移动平均**来计算历史梯度的平方，防止学习率过快衰减。 | 解决 AdaGrad 的学习率衰减问题，通常比 AdaGrad 效果好。       |
| **AdaDelta** | **AdaDelta**                               | 进一步改进 RMSprop，**不需要手动设置全局学习率**，而是使用历史更新量和历史梯度来动态调整。 | 鲁棒性强，但不如 Adam 常用。                                 |

4. 结合型优化器（最常用）

这类优化器结合了动量和自适应学习率的优点，是目前深度学习任务中最主流的选择。

| **优化器** | **简称**                              | **核心机制**                                                 | **特点和应用场景**                                           |
| ---------- | ------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **Adam**   | **Adam** (Adaptive Moment Estimation) | 结合了 **动量**（一阶矩估计，梯度的均值）和 **RMSprop**（二阶矩估计，梯度平方的均值）。 | **收敛速度快，鲁棒性强**。是目前**最常用**的默认优化器，适用于绝大多数深度学习任务。 |
| **AdamW**  | **AdamW**                             | Adam 的变体。它将权重衰减（Weight Decay，一种正则化技术）从梯度更新中分离出来（解耦）。 | 在许多任务中，特别是**大模型（如 Transformer）**上，AdamW 表现优于 Adam，泛化能力更强。 |
| **Nadam**  | **Nadam**                             | 结合了 **Adam** 和 **Nesterov 动量**。                       | 在某些情况下比 Adam 表现更好，但计算略复杂。                 |



### 如何选择优化器？

- **默认首选：** 对于大多数新的任务，通常从 **Adam** 或 **AdamW** 开始。它们易于使用且性能稳健。
- **需要精调性能：** 如果 Adam/AdamW 效果不佳或需要更强的泛化能力，可以尝试使用 **SGD with Momentum**，并仔细调整学习率（可能需要配合学习率调度器）。
- **稀疏数据：** 如果您的数据非常稀疏（例如 NLP 中的词嵌入），可以考虑 **AdaGrad** 或其变体。
- **GANs 等不稳定任务：** 在生成对抗网络 (GAN) 等对优化稳定性要求高的任务中，Adam 虽然常用，但有时需要配合特殊的学习率调度。



优化器（Optimizer）在深度学习训练中的作用是**核心且至关重要**的，它是连接**梯度计算（反向传播）**和**参数调整（模型学习）**的桥梁。

简而言之，优化器的作用就是**指导模型如何根据计算出的梯度来更新参数，以最小化损失函数。**



### 优化器的核心作用可以概括为以下三点：

#### 1. 最小化损失函数 (Minimizing the Loss)

这是优化器的**根本目标**。

- **原理：** 损失函数（Loss Function）衡量模型预测结果和真实值之间的误差。训练的目标就是找到一组模型参数（权重 W 和偏置 b），使得这个损失值达到全局（或局部）最小值。
- **实现：** 优化器通过迭代地调整 W 和 b，沿着损失曲面下降最快的方向（即梯度的反方向）移动，直到找到最优参数。



#### 2. 参数更新的执行者 (Executing Parameter Updates)



优化器负责将反向传播计算的结果转化为实际的参数调整。

- **输入：** 接收来自反向传播计算出的所有参数的梯度 frac{\partial L}{\partial W}。
- **计算：** 根据其特定的**优化算法**（如 SGD、Adam 等）来计算每个参数的新值。
- **输出：** 将模型的所有参数 W 和 b 更新为新值，以准备进行下一个训练步骤。



#### 3. 决定学习效率和质量 (Controlling Learning Dynamics)



不同的优化器算法决定了参数更新的方式、步长和速度，从而直接影响模型的训练效率和最终性能。

- **学习率（步长）：** 优化器定义了学习率 alpha（Learning Rate），即沿着负梯度方向迈出的步子有多大。
  - **基础优化器：** 使用固定的学习率。
  - **自适应优化器：** （如 Adam）为**每个参数**动态地分配和调整学习率，这有助于在复杂地形（如鞍点）中更快地找到最小值。
- **惯性/动量（Momentum）：** 许多优化器（如 Adam 和 SGD with Momentum）通过引入动量来平滑更新路径，减少震荡，并帮助模型加速通过平坦区域或跳出局部最优。



### 总结公式（以最基础的 SGD 为例）：

text{新的} W \leftarrow \text{旧的} W - \text{学习率} \times \frac{\partial L}{\partial W}

优化器就是执行这个减法操作的算法，它定义了如何选择**学习率**以及如何计算**减去的量**，确保模型能够有效且稳定地学习。





学习率.：控制权重更新的幅度，影响收敛速度  大小决定了在正确的方向迈多大的步子。





动量法（Momentum）是梯度下降优化算法中一种非常有效的改进策略。在动量法中，“动量”的作用可以概括为两个核心方面：**加速收敛** 和 **抑制震荡**。

它借鉴了物理学中动量的概念，让优化过程像一个滚下山坡的球一样：球在运动过程中会积累惯性，即使遇到小坡也不会停下来，并且会持续加速

### 作用一：加速收敛（解决“平坦区域”问题）

在标准的随机梯度下降（SGD）中，每一步的更新只依赖于当前批次数据的梯度。如果损失函数曲面存在大片的平坦区域（即梯度很小），SGD 将以极慢的速度前进。

- **动量法的实现：** 动量法引入了一个“历史速度”（或称为**动量项 v**），它结合了**上一次的更新方向**和**当前的梯度**。
  - **公式：** 新的速度 v_{\text{new}} 是由上一次的速度 v_{\text{old}} 乘上一个**动量系数**（beta 或 gamma）再加上当前梯度 frac{\partial L}{\partial W} 得到的。
- **效果：**
  - 当连续多个步骤的梯度方向都相同时（例如在长而平坦的斜坡上），动量项会**累积**，导致速度 v 越来越大，从而**加速**模型在这一方向上的前进，大大缩短了收敛时间。

### 作用二：抑制震荡（解决“陡峭山谷”问题）

在复杂的损失函数曲面中，常常存在“狭窄且陡峭的山谷”：在这个区域内，损失函数在某个维度（例如垂直于山谷方向）的梯度很大，但在另一个维度（沿着山谷方向）的梯度很小。

- **标准 SGD 的问题：** 在这种山谷中，标准 SGD 会在两侧剧烈地来回“震荡”，浪费大量时间，而且向目标前进的速度却很慢。
- **动量法的效果：**
  - **垂直方向（大梯度）：** 由于两侧梯度方向相反（一会指向左，一会指向右），动量项会在垂直方向上相互抵消，使得垂直方向的更新幅度大大减小，**抑制了不必要的震荡**。
  - **水平方向（小梯度）：** 在沿着山谷底部前进的方向上，梯度方向保持一致，动量得以累积，**保证了前进的速度**。



### 总结：动量项的数学角色

动量项 v 扮演了梯度的**指数加权平均**角色。

1. 计算动量/速度 v：

   v \leftarrow \beta \cdot v + \frac{\partial L}{\partial W}

   - beta（动量系数，通常设为 0.9）：控制历史梯度的影响程度。

2. 更新权重 W：

   W \leftarrow W - \alpha \cdot v

   - alpha：学习率。

通过这种方式，动量法使每次更新方向不仅取决于当前的梯度，还取决于历史梯度的平均趋势，从而实现**更平滑、更快速、更稳定**的收敛。









### 阶段一：前向传播（Forward Pass）—— 构建计算图



**目标：** 计算网络的输出，并衡量输出与真实标签的差异（即计算损失）。

1. **输入数据：** 输入数据 X (一个批次) 经过网络的第一层。

2. 逐层计算： 信号从输入层向前传递，依次通过每一层的权重矩阵 W 和激活函数 σ。

   

   Z^{[l]} = W^{[l]} A^{[l-1]} + b^{[l]}

   A^{[l]} = sigma(Z^{[l]})

   

3. **记录操作：** 在这个过程中，深度学习框架（如 PyTorch）的 **自动求导系统** 会动态地记录下每一次操作（矩阵乘法、加法、激活函数等），形成一个完整的**计算图**。这个图是未来反向计算梯度的蓝图。

4. **计算损失：** 最后一层输出 hat{Y} 后，与真实标签 Y 计算损失函数 L（例如均方误差 MSE 或交叉熵 Cross-Entropy）。



### 阶段二：反向传播（Backward Pass）—— 计算梯度



**目标：** 从损失 L 开始，逆向应用链式法则，计算 L 对每一层权重 W 的梯度 frac{partial L}{partial W}。

#### 1. 启动反向计算

从计算图的终点（损失 L）开始，对损失张量调用 `.backward()` 方法（PyTorch 语法），启动梯度计算。

#### 2. 链式法则的应用

算法从最后一层（L 对 hat{Y}）开始，逐层向后传递**上游梯度**，并乘以**局部梯度**。

- **起点（最后一层）：** 首先计算损失 L 对网络最终输出 hat{Y} 的梯度 frac{partial L}{partial hat{Y}}。

- **向后传递：** 考虑网络中的任意一层 l，我们想计算损失 L 对该层权重 W^{[l]} 的梯度。

  - **局部梯度：** 每一层的操作都有一个预先定义好的“反向函数”，负责计算该操作的**局部偏导数**。例如，如果 Z = WA + b，那么 frac{partial L}{partial W} 的局部因子就是 frac{partial Z}{partial W} = A^T。
  - **链式相乘：** 算法将**上游传来的梯度**（即 frac{partial L}{partial Z^{[l]}}）与该层的**局部梯度**（frac{partial Z^{[l]}}{partial W^{[l]}}）相乘，得到最终梯度：

  frac{partial L}{partial W^{[l]}} = frac{partial L}{partial Z^{[l]}} cdot frac{partial Z^{[l]}}{partial W^{[l]}}

#### 3. 梯度存储

计算出的梯度 frac{partial L}{partial W} 会自动存储在对应权重张量 W 的 `.grad` 属性中，等待优化器使用。



### 阶段三：参数更新（Optimization）—— 使用梯度

**目标：** 利用计算出的梯度，按照优化器的规则来微调权重，以减小损失 L。

1. **优化器选择：** 训练时通常选择 SGD、Adam、RMSprop 等优化器。

2. **权重更新：** 优化器根据其自身的算法和**学习率 (alpha)**，使用计算出的梯度来更新所有参数。

   - 最基本的更新公式（梯度下降）：

     text{新的} W leftarrow text{旧的} W - alpha cdot frac{partial L}{partial W}

3. **清零梯度：** 在下一个训练周期开始前，必须手动将所有参数的 `.grad` 属性清零（例如 PyTorch 中的 `optimizer.zero_grad()`）。这是因为梯度是累加的，不清零会导致新计算的梯度错误地叠加到前一次的值上。







archive   akaiv

scholar  skaole



## 一、基础和传统结构

### 1. 前馈神经网络（Feedforward Neural Network, FNN） / 多层感知机（Multi-Layer Perceptron, MLP）

- **结构：** 由**输入层**、至少一个**隐藏层**和**输出层**组成。

- **信息流：** 信息只朝一个方向流动，即从输入层经过隐藏层到达输出层，层间没有循环连接。

- **用途：** 最基础的结构，适用于分类、回归等任务，处理表格数据或特征向量。

  

  ### 2. 自动编码器（Autoencoders, AE）

  

  - **结构：** 一种特殊的 FNN，由**编码器（Encoder）**和**解码器（Decoder）**组成。
  - **目标：** 学习输入数据的**压缩表示（Code/Latent Space）**，目标是使输出重建（Reconstruct）输入。
  - **用途：** 降维、特征学习、去噪（降噪自动编码器 Denoising AE）。

  ------

  

  ## 二、 序列数据结构（用于时间、文本）

  

  

  ### 3. 循环神经网络（Recurrent Neural Network, RNN）

  

  - **结构：** 神经元之间具有**循环（反馈）连接**，允许信息从一个时间步传递到下一个时间步。
  - **特点：** 具有“记忆”能力，能处理**序列数据**（如文本、时间序列）。
  - **缺点：** 容易出现**梯度消失或爆炸**问题，难以捕捉长距离依赖。

  

  ### 4. 长短期记忆网络（Long Short-Term Memory, LSTM） / 门控循环单元（Gated Recurrent Unit, GRU）

  

  - **结构：** RNN 的变体，通过引入**门控机制（Gate Mechanism）**——如输入门、遗忘门、输出门——来精确控制信息在时间步上的流动和保留。
  - **特点：** 有效解决了传统 RNN 的梯度消失问题，能够更好地捕捉序列中的**长期依赖关系**。
  - **用途：** 语音识别、机器翻译、文本生成、时间序列预测。

  ------

  

  ## 三、 视觉数据结构（用于图像、视频）

  ### 5. 卷积神经网络（Convolutional Neural Network, CNN）

  

  - **结构：** 核心是**卷积层（Convolutional Layer）**、**池化层（Pooling Layer）\**和\**全连接层**。
  - **特点：** 通过**局部连接**和**权值共享**的方式高效地提取空间特征。卷积核就像滑动在图像上的滤波器。
  - **用途：** 图像识别、物体检测、图像分割、计算机视觉领域的主流架构。

  

  ### 6. 反卷积神经网络（Deconvolutional Neural Network / Transposed CNN）

  

  - **结构：** 可以看作是 CNN 的逆过程，用于将低维特征图恢复或**上采样**到高分辨率图像。
  - **用途：** 图像生成、图像分割（例如在 UNet 结构中）、图像重建。

  ------

  

  ## 四、 现代与先进结构

  

  

  ### 7. Transformer（变压器）

  - **结构：** 完全基于**自注意力机制（Self-Attention Mechanism）**的架构，通常由**编码器（Encoder）**和**解码器（Decoder）**组成。
  - **特点：** 彻底抛弃了循环和卷积结构，能够并行处理整个序列，并在计算上高效地捕捉序列中任意两个元素之间的依赖关系（全局依赖）。
  - **用途：**
    - **NLP 领域主流：** BERT、GPT 系列等大型语言模型（LLM）。
    - **CV 领域应用：** Vision Transformer (ViT) 通过将图像切分成块（Patch）并作为序列输入，证明了其在图像任务上的有效性。

  

  ### 8. 图神经网络（Graph Neural Network, GNN）

  - **结构：** 专门设计用来处理**图结构数据**（数据点是节点，连接是边）。
  - **原理：** 通过在图的节点及其邻居之间传递和聚合信息来学习节点的表示。
  - **用途：** 社交网络分析、推荐系统、化学分子结构分析。

  

  ### 9. 混合架构

  许多高性能模型会结合多种结构的优点：

  - **CNN-RNN 组合：** 常见于视频处理（CNN 提取帧特征，RNN 处理时间序列）。
  - **UNet：** 结合了卷积（收缩路径）和反卷积（扩张路径）的结构，常用于医学图像分割。
  - **大型多模态模型：** 例如 VLA 模型（您之前提到的）结合了 Transformer（处理语言）和 CNN/ViT（处理视觉）的组件。

、







导入语句集合展示了一个典型且完整的**具身智能项目**所需的技术栈：它使用了 **PyTorch/Tensor** 进行深度学习，依赖 **NumPy/SciPy** 进行数值和空间计算，通过 **OpenCV/PIL** 处理图像，使用 **PyBullet** 进行仿真，并利用 **`lerobot`** 框架专为 VLA 模型定制的工具链进行高效的数据加载、模型管理和策略部署。





多模态输入：

 **Perceptual Transformer**  多模态transformer

图像输入： 多视图、多时间步RGB图像，双线性插值（图像预处理）图像堆叠技术

机器人状态：Min-Max 归一化/反归一化用于将机器人状态或动作从原始的物理范围归一化到 [-1, 1]

训练：

扩散模型（ diffusion model）：**生成动作序列**：模型训练目标是学习逆向扩散过程，即从高斯噪声中恢复出真实的动作序列（**行动块**）。

**扩散损失****分数匹配损失** (Denoising Score Matching Objective)，特别是 **EDM Loss****训练目标**：通过最小化模型预测的噪声与实际添加的噪声之间的差异（如均方误差 text{MSE}），来训练去噪网络。代码中通过 `self.model.loss` 实现

噪声调度 (训练)：采样密度函数 (`make_sample_density`)，**噪声级别采样**：用于在训练时从 text{sigma\_min} 到 text{sigma\_max} 之间采样噪声级别 sigma。默认使用 **Log-Logistic 分布**（`rand_log_logistic`）作为采样密度，以确保模型在不同噪声水平上都能有效学习

**生成流模型 (Generative Flow Model)**：`self.gen_flow`**预测视觉轨迹**：学习在潜在空间中预测未来的视觉变化 text{track}。通过最小化 **text{flow\_gen\_loss}**，增强潜在表征的前瞻性。

text{masked\_beta}用于平衡**动作损失**和**视觉生成损失**的超参数，控制多任务学习中的损失权重。



、VLA、多模态transformer 接收多视图多时间步的RGB图像（obs） 接收文本指令、接收机器人状态位姿  融合输出一个统一的潜在表征





好的，我来详细解释一下“光流轨迹信息”和“生成语言指令的语义嵌入”在您这段数据预处理代码中是如何工作的，以及光流轨迹信息的具体含义。

take_tracker.py

原始数据转换为模型可用的训练数据

加载.h5数据，光流提取（随机点和网格点）的轨迹和可视性track_through_video函数，归一化，更新h5保存。  SBERT对语言编码，更新h5保存。



track_through_video：

使用 CoTracker 模型，在给定的视频上生成并优化一组高质量、具有代表性的光流轨迹和其可视性数据

单个视频：

随机采样+过滤 1000个，确保捕捉最活跃、最显著的物体（高方差轨迹）

**网格采样 + 保留**：7*7网格*2，确保轨迹**均匀覆盖**整个画面，即使在运动不明显的区域也有采样，作为环境的完整表征。

随机时间t开始：

1、增加数据的多样性、都从t=0开始，过度依赖时间序列开始状态，忽略中间帧能力。2、模拟真实场景，任何时刻机器人都可能要去关注新出现的物体，随机时刻可以让它在任何位置准确初始化保持跟踪能力 3、**时序上的数据增强**。通过从不同时间点开始跟踪，可以有效地增加用于训练的轨迹样本的多样性。

#### B. 提高 CoTracker 的鲁棒性

- CoTracker 是一种**时空模型**，它同时处理整个视频。虽然它能看到整个序列，但查询点 $(t, y, x)$ 告诉模型：“请从第 $t$ 帧的 $(y, x)$ 坐标开始，计算它在**整个视频**中的轨迹。”
- 随机 $t$ 确保了模型的**时间泛化能力**，使其能稳定地跟踪跨越任意时间段的轨迹，而不仅仅是那些从头到尾都存在的轨迹。



噪声注入5%：

在过滤了低方差点并重新选择了高质量点之后注入，提高轨迹鲁棒性、泛化性。 一种数据增强技术。

#### A. 提高模型对初始位置扰动的鲁棒性

**感知噪声：** 传感器或关键点检测器定位不完美的场景

**跟踪初始化误差：** 即使是最高质量的点，其在起始帧的位置也可能有微小偏差。

**训练更强的模型：** 当 CoTracker 模型用这些带噪声的查询点重新训练时，它被迫去学习**即使起始位置略有偏差，也能找到并保持正确的轨迹**的能力。这使得模型在面对真实世界的微小扰动时更加鲁棒。

#### B. 促进点集多样性（重采样补充）

- 在 `track_and_remove` 内部，高质量点首先被平铺 (`torch.tile`) 来恢复数量。平铺操作只是简单复制。
- 噪声注入确保了这些复制的点在空间上**不是完全相同的**。它们变成了彼此**微小位移**的版本。
- 这有助于 CoTracker 探索高质量特征点周围的邻域，潜在地发现附近更可靠的跟踪路径，同时保持了轨迹整体的高质量。

随机时间 $t$ 增强了时间上的泛化性，而噪声注入增强了空间位置上的鲁棒性





## 光流轨迹信息 (Optical Flow Tracks)

想·

**光流轨迹 (Optical Flow Tracks)** 则是将这个运动信息扩展到**整个时间序列**。它记录了图像中的一个或一组特定的像素点，在其后的多帧图像中**连续移动的像素坐标序列**。

提供了：物体运动的显式线索、时间一致性（模型理解长时间的行为序列）

依赖CoTracker模型

**输入：**

- **视频 (`video`)：** 形状为 T * C * H  * W（时间、通道、高度、宽度）的多帧图像。
- **查询点 (`queries`)：** 一组在视频中的**起始点**。代码通过 `sample_from_mask`（随机点）和 `sample_double_grid`（网格点）在视频的 T 帧中采样了起始时间、X 坐标、Y 坐标。

**CoTracker 模型：** 这是一个先进的深度学习模型，专门用于**稠密且鲁棒**地跟踪图像中的点。

**输出 (`pred_tracks`, `pred_vis`)：**

- **`pred_tracks` (轨迹)：** 形状为 [1, T, N, 2] 的张量。它记录了 N 个查询点在视频的 T 帧中每一帧的像素坐标 (x, y)。
- **`pred_vis` (可视性)：** 形状为 [1, T, N] 的张量。它指示了对应的轨迹点在每一帧中是否**可见或可信**。如果点被遮挡、离开视野或跟踪失败，可视性会很低。

**后处理与保存：**

- **过滤：** 代码通过计算轨迹的**方差** (`torch.var`) 来过滤掉几乎不动的点，确保只保留有意义的运动轨迹。
- **归一化：** 像素坐标被归一化到 {[0, 1]} 范围（`pred_tracks[:, :, :, 0] /= W`），这是深度学习模型常用的做法，以消除图像分辨率的影响。
- **保存：** 最终的轨迹和可视性数据被保存为 `.npy` 文件，并将路径写入 `.h5` 文件。



## 基于pytorch-lightning 和 hydra构建的深度学习训练

全局随机种子,确保可复现



obs(V T C H W)

hdf5_use_v2.2.py  

 Parquet 文件存储状态和动作，视频单独存放转换成一个易于深度学习模型加载的、结构化的 HDF5 格式

拿到所有末端位姿，然后获取末端执行器的动作差：Delta eef  二值化夹爪 拼接 成data_dict[action]

从episodes.jsonl提取语言指令，并添加到data_dict  





FID 主要用于**衡量生成模型（如扩散模型、GANs 等）所生成的图像的质量和真实性**。

弗雷歇起始距离 

SOTA 最先进的





track_patch_embed.py

处理时间序列数据，传统transformer图像切分patch的概念应用到时间维度。 把长段轨迹数据，沿时间轴切成更短的patch，每个时间块特征提取和压缩

压缩时间维度，增大特征维度（嵌入特征），特征被提炼增强







什么是卷积？

假设输入的数据是一条很长的路。

卷积核就是小小模板，模板通过滑窗乘加方式，把模板在路从头到尾贴一遍。算出来N个总分。

高分表示路面图案和模板图案相似度高。低分相反。（某局部模式的特征图）

结果得到一个这条路和模板图案相似度的检测报告。

Conv1D用多个时间模板扫轨迹的时间序列，来提取出“加速转弯停顿”等局部行为模式，并把这些模式浓缩到时间块特征向量。

Stride 步长：每次卷积核滑动多少元素

Output Channels卷积核数量： 多少中模式多少个卷积核



卷积核（类似模板）：学习到的、用来检测特定模式的小矩阵。

卷积：用这个模板扫描整个数据，具体提取特征。

具体实现细节：

1个批次，每个轨迹有32个时间步，总共10条轨迹，每个有4个原始特征维度（xy位置和速度），目标的每个时间patch有8帧图像，目标嵌入的特征维度是64。

第一步重排，变成1*10 10个批次，每个批次4个通道，长度32。

第二步卷积，卷积核配置输入通道C=4 输出通道D=64， 卷积核大小为8，步长为8.

把每个点轨迹32帧降低到4帧。



Patch Embedding





池化层 通常跟在卷积层后，用于**减小特征图的尺寸**，从而减少计算量和参数数量，并提高模型的鲁棒性。

“压缩器和过滤器”，对已发现信息进行提炼简化。







clip_tokenizer 文本分词器 BPE

​	



Markov Decision Process 马尔科夫决策过程MDP





技术架构师 /系统架构师

 我们的架构师不行（没见过特别行的，可能是行业起步的问题）

技术选型  顶层设计

主要技术方案都没法论证/没经过论证， 都是主要看论文来推测可行性。









好的，我来用大白话和清晰的对比表格，把 DDPM（去噪扩散概率模型）和 Flow Matching（流匹配）这两个目前最先进的生成模型算法的区别给您讲清楚。

------



## 核心区别：确定性 vs 随机性



理解 DDPM 和 Flow Matching 最关键的区别在于它们如何看待**“从噪声变到图像”**这个过程的本质：

| 算法              | 核心思想 (大白话)                | 数学本质                   | 采样速度/性质               |
| ----------------- | -------------------------------- | -------------------------- | --------------------------- |
| **DDPM**          | **“教模型如何倒着解散”**         | 基于**随机微分方程 (SDE)** | 慢 (传统上千步)，**随机**   |
| **Flow Matching** | **“教模型如何以最直的路线雕刻”** | 基于**常微分方程 (ODE)**   | 快 (通常几十步)，**确定性** |

导出到 Google 表格

------



## 1. DDPM（去噪扩散概率模型）：倒着解散的过程





### 算法大白话解读



想象你有一张清晰的照片（数据），你不停地往上撒**随机的雪花（噪声）**，直到照片完全变成一片白茫茫的雪景（纯噪声）。

- **训练阶段（前向过程）：** DDPM 固定这个**撒雪花**的过程。
- **学习目标（反向过程）：** 你的模型要学习的是**逆转**这个过程——它要学会如何从每一片雪景中**“识别出并擦掉”**刚刚撒上的那一层雪花，从而一步一步**恢复**出清晰的照片。
- **训练难度：** 每次擦雪花，模型都需要猜测**“正确的去噪方向和力度”**，这个猜测本身带有**随机性**（SDE）。所以训练目标比较复杂，涉及到**得分匹配**等概念。
- **生成（采样）阶段：** 随机从纯雪景开始，模型每次加入一点随机的波动（符合 SDE 过程），然后进行去噪。因为每一步都有随机波动，所以**路径是弯曲的**，需要很多步（比如 1000 步）才能得到高质量的结果。



### 关键特点总结



- **随机性强：** 训练和传统的采样过程都依赖随机性，因此生成的**多样性好**。
- **速度较慢：** 原始 DDPM 采样速度慢，需要数百到上千个去噪步骤。
- **基石地位：** 是目前所有主流 AI 绘画模型（如 Stable Diffusion）的数学基础。

------



## 2. Flow Matching（流匹配）：设计最直的路径





### 算法大白话解读



Flow Matching 抛弃了“雪花随机波动”的想法，转而使用“雕塑”的比喻：

想象你有一个泥团（纯噪声），你想把它雕刻成一座精美的雕像（数据）。

- **核心思想：** Flow Matching 不学习去噪，而是学习**雕刻的“手速和方向”**，也就是**速度场** ut(Xt)。它想要找到一条**从泥团到雕像之间最直接、最平滑、最确定的路径**。
- **训练阶段：** 模型不学习消除噪声，而是学习**“如何推动样本以沿着这条最短路径移动”**。它直接将神经网络预测的**瞬时速度**与这条理想路径的瞬时速度进行**匹配（Matching）**。
- **训练优势：** 这种直接匹配速度场的训练目标，比 DDPM 学习随机去噪要**简单、稳定**得多。
- **生成（采样）阶段：** 从泥团开始，模型沿着学习到的**确定性**的速度场 ut 移动。由于路径是设计好的**最短路径（最直的流）**，它可以使用高效的数学方法（ODE 求解器）在**极少的步骤内**（比如 10 ∼ 50 步）完成雕刻。



### 关键特点总结



- **确定性强：** 采样过程是**确定性**的（给定起始噪声，结果不变）。
- **速度极快：** 由于路径笔直且确定，可以使用高效的 ODE 求解器，生成速度比原始 DDPM 快得多。
- **训练稳定：** 训练目标是一个简单的**回归损失**，因此训练过程通常比 DDPM 更稳定。

------
